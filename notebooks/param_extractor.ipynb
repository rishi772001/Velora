{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§¾ Parameter Extraction using FLAN-T5\n",
    "**Task:** Extract structured parameters from natural language\n",
    "**Model:** `google/flan-t5-small`\n",
    "**Optimized for:** Few-shot prompting or fine-tuning\n",
    "**Resources:** Free-tier Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Step 1: Load Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"google/flan-t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Step 2: Inference with Few-Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_params(prompt):\n",
    "    input_text = f\"\"\"\n",
    "You are an assistant that extracts flight booking details from the user input below and identifies missing information.\n",
    "\n",
    "Extract the following parameters if present: \"destination\", \"date\", \"departure_city\", \"number_of_passengers\".\n",
    "\n",
    "Then generate a JSON object with two keys:\n",
    "- \"extracted\": containing the extracted parameters and their values,\n",
    "- \"questions\": a list of questions to ask the user for any missing parameters.\n",
    "\n",
    "Format the output as JSON.\n",
    "\n",
    "User input: \"{prompt}\"\n",
    "\n",
    "Output:\n",
    "\"\"\"\n",
    "\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=64,\n",
    "        num_beams=5,\n",
    "        early_stopping=True,\n",
    "        temperature=0\n",
    "    )    \n",
    "    result = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the function\n",
    "extract_params(\"Book a flight to Paris next week\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
